{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from ge.classify import read_node_label, Classifier\n",
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from ge import DeepWalk\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "from ge import LINE\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proximity_score(G, edges,feature):\n",
    "    jc_list = [[] for i in itertools.repeat(None, len(edges))]\n",
    "    pa_list = [[] for i in itertools.repeat(None, len(edges))]\n",
    "    adar_list = [[] for i in itertools.repeat(None, len(edges))]\n",
    "    jc = nx.jaccard_coefficient(G, edges)\n",
    "    pa = nx.preferential_attachment(G, edges)\n",
    "    cn = [len(list(nx.common_neighbors(G, edge[0], edge[1]))) for edge in edges]\n",
    "    for i, data in enumerate(jc):\n",
    "        jc_list[i]=data[2]\n",
    "    for i, data in enumerate(pa):\n",
    "        pa_list[i]=data[2]\n",
    "    \n",
    "    if feature == 'jc':\n",
    "        return jc_list\n",
    "    elif feature == 'pa':\n",
    "        return pa_list\n",
    "    elif feature == 'cn':\n",
    "        return list(cn)\n",
    "    else:\n",
    "        return jc_list,pa_list,list(cn) \n",
    "    return jc_list,pa_list,list(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    return sum(1 for x, y in zip(prediction, label) if x == y) / len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df=pd.read_csv('facebook_edges.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_G = nx.from_pandas_edgelist(ori_df, 'id_1', 'id_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train_pos_data.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>id_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12924</td>\n",
       "      <td>21054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16427</td>\n",
       "      <td>2768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10187</td>\n",
       "      <td>17328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4382</td>\n",
       "      <td>6128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85496</th>\n",
       "      <td>365</td>\n",
       "      <td>13286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85497</th>\n",
       "      <td>1803</td>\n",
       "      <td>3862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85498</th>\n",
       "      <td>1387</td>\n",
       "      <td>19483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85499</th>\n",
       "      <td>3743</td>\n",
       "      <td>6741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85500</th>\n",
       "      <td>9053</td>\n",
       "      <td>19522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85501 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_1   id_2\n",
       "0      12924  21054\n",
       "1      16427   2768\n",
       "2       1969   2239\n",
       "3      10187  17328\n",
       "4       4382   6128\n",
       "...      ...    ...\n",
       "85496    365  13286\n",
       "85497   1803   3862\n",
       "85498   1387  19483\n",
       "85499   3743   6741\n",
       "85500   9053  19522\n",
       "\n",
       "[85501 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_G = nx.from_pandas_edgelist(train_df, 'id_1', 'id_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 20214\n",
      "Number of edges: 85501\n",
      "Average degree:   8.4596\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(train_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list(ori_G.nodes))):\n",
    "    train_G.add_node(list(ori_G.nodes)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 22470\n",
      "Number of edges: 85501\n",
      "Average degree:   7.6102\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(train_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_edges = [(data.id_1, data.id_2) for data in train_df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['jc'],train_df['pa'],train_df['cn'] = get_proximity_score(train_G, pos_edges,'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>id_2</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>cn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12924</td>\n",
       "      <td>21054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16427</td>\n",
       "      <td>2768</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>616</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>2239</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>594</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10187</td>\n",
       "      <td>17328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4382</td>\n",
       "      <td>6128</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>495</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85496</th>\n",
       "      <td>365</td>\n",
       "      <td>13286</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85497</th>\n",
       "      <td>1803</td>\n",
       "      <td>3862</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>814</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85498</th>\n",
       "      <td>1387</td>\n",
       "      <td>19483</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>3584</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85499</th>\n",
       "      <td>3743</td>\n",
       "      <td>6741</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>165</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85500</th>\n",
       "      <td>9053</td>\n",
       "      <td>19522</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85501 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_1   id_2        jc    pa  cn\n",
       "0      12924  21054  0.000000   232   0\n",
       "1      16427   2768  0.036585   616   3\n",
       "2       1969   2239  0.062500   594   3\n",
       "3      10187  17328  0.000000   162   0\n",
       "4       4382   6128  0.170732   495   7\n",
       "...      ...    ...       ...   ...  ..\n",
       "85496    365  13286  0.021277   215   1\n",
       "85497   1803   3862  0.282609   814  13\n",
       "85498   1387  19483  0.011236  3584   3\n",
       "85499   3743   6741  0.238095   165   5\n",
       "85500   9053  19522  0.052632    99   1\n",
       "\n",
       "[85501 rows x 5 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_df=pd.read_csv('test_pos_data.csv',header=0)\n",
    "test_pos_edges=[(data.id_1, data.id_2) for data in test_pos_df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_df['jc'],test_pos_df['pa'],test_pos_df['cn'] = get_proximity_score(train_G, test_pos_edges,'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"negative_edges.p\",\"rb\")\n",
    "negative_edges = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = pd.DataFrame(list(negative_edges), columns=['id_1', 'id_2'])\n",
    "neg_edges = list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg['jc'],df_neg['pa'],df_neg['cn'] = get_proximity_score(train_G, neg_edges,'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_neg,X_test_neg = train_test_split(df_neg, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pos=np.ones(len(train_df))\n",
    "y_train_neg=np.zeros(len(X_train_neg))\n",
    "y_test_pos=np.ones(len(test_pos_df))\n",
    "y_test_neg=np.zeros(len(X_test_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((train_df,X_train_neg))\n",
    "y_train = np.concatenate((y_train_pos,y_train_neg))\n",
    "X_test = np.concatenate((test_pos_df,X_test_neg))\n",
    "y_test = np.concatenate((y_test_pos,y_test_neg)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=400)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=400)\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8566449515210348\n"
     ]
    }
   ],
   "source": [
    "#jc,pa,cn\n",
    "predict_Y = clf1.predict(X_test)\n",
    "print(get_accuracy(predict_Y, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8448205284148723\n"
     ]
    }
   ],
   "source": [
    "#jc\n",
    "predict_Y = clf1.predict(X_test)\n",
    "print(get_accuracy(predict_Y, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8041718810306312\n"
     ]
    }
   ],
   "source": [
    "#pa\n",
    "predict_Y = clf1.predict(X_test)\n",
    "print(get_accuracy(predict_Y, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8443702412837277\n"
     ]
    }
   ],
   "source": [
    "#cn\n",
    "predict_Y = clf1.predict(X_test)\n",
    "print(get_accuracy(predict_Y, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2v_embedding(train_G):  #https://github.com/eliorc/node2vec\n",
    "    node2vec  = Node2Vec(train_G, dimensions=128, walk_length=80, num_walks=10, workers=4,p=0.25,q=0.25)\n",
    "    model = node2vec .fit(window=10, min_count=1, batch_words=4)\n",
    "    edges_embs = HadamardEmbedder(keyed_vectors=model.wv)\n",
    "    return edges_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████████████████████████████████| 22470/22470 [00:15<00:00, 1441.17it/s]\n"
     ]
    }
   ],
   "source": [
    "edges_embs = n2v_embedding(train_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(edges_embs ,open(\"edges_embs_paper2.p\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"edges_embs_paper2.p\",\"rb\")\n",
    "embeddings = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<node2vec.edges.HadamardEmbedder at 0x1b01ba95700>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2v_combine_embedding(data):\n",
    "    i=0\n",
    "    X = []\n",
    "    for edge in data:\n",
    "        X.append(np.concatenate((data[i],embeddings[(str(int(edge[0])), str(int(edge[1])))])))\n",
    "   # print(embeddings[str(int(data[0]))])\n",
    "        i+=1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train_pos_data.csv',header=0)\n",
    "test_pos_df=pd.read_csv('test_pos_data.csv',header=0)\n",
    "df_neg = pd.DataFrame(list(negative_edges), columns=['id_1', 'id_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.values\n",
    "test_pos_df=test_pos_df.values\n",
    "df_neg=df_neg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=n2v_combine_embedding(train_df)\n",
    "test_pos_df=n2v_combine_embedding(test_pos_df)\n",
    "df_neg=n2v_combine_embedding(df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_neg,X_test_neg = train_test_split(df_neg, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pos=np.ones(len(train_df))\n",
    "y_train_neg=np.zeros(len(X_train_neg))\n",
    "y_test_pos=np.ones(len(test_pos_df))\n",
    "y_test_neg=np.zeros(len(X_test_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((train_df,X_train_neg))\n",
    "y_train = np.concatenate((y_train_pos,y_train_neg))\n",
    "X_test = np.concatenate((test_pos_df,X_test_neg))\n",
    "y_test = np.concatenate((y_test_pos,y_test_neg)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=400)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators=400)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9115507420965837\n"
     ]
    }
   ],
   "source": [
    "#node2vec\n",
    "predict_Y2 = clf2.predict(X_test)\n",
    "print(get_accuracy(predict_Y2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9074513748377212\n"
     ]
    }
   ],
   "source": [
    "#jc,pa,cn,node2vec\n",
    "predict_Y2 = clf2.predict(X_test)\n",
    "print(get_accuracy(predict_Y2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_embedding(data,embeddings):\n",
    "    i=0\n",
    "    X = []\n",
    "    for node1,node2 in data:\n",
    "        X.append(np.concatenate((data[i],embeddings[int(node1)],embeddings[int(node2)])))\n",
    "   # print(embeddings[str(int(data[0]))])\n",
    "        i+=1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train_pos_data.csv',header=0)\n",
    "test_pos_df=pd.read_csv('test_pos_data.csv',header=0)\n",
    "df_neg = pd.DataFrame(list(negative_edges), columns=['id_1', 'id_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.values\n",
    "test_pos_df=test_pos_df.values\n",
    "df_neg=df_neg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LINE(train_G, embedding_size=128, order='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 - 5s - loss: 1.3863 - first_order_loss: 0.6931 - second_order_loss: 0.6931\n",
      "Epoch 2/50\n",
      "51/51 - 5s - loss: 1.3851 - first_order_loss: 0.6927 - second_order_loss: 0.6924\n",
      "Epoch 3/50\n",
      "51/51 - 5s - loss: 1.3814 - first_order_loss: 0.6920 - second_order_loss: 0.6894\n",
      "Epoch 4/50\n",
      "51/51 - 5s - loss: 1.3610 - first_order_loss: 0.6914 - second_order_loss: 0.6696\n",
      "Epoch 5/50\n",
      "51/51 - 6s - loss: 1.2899 - first_order_loss: 0.6899 - second_order_loss: 0.6000\n",
      "Epoch 6/50\n",
      "51/51 - 6s - loss: 1.1730 - first_order_loss: 0.6886 - second_order_loss: 0.4844\n",
      "Epoch 7/50\n",
      "51/51 - 6s - loss: 1.1010 - first_order_loss: 0.6852 - second_order_loss: 0.4158\n",
      "Epoch 8/50\n",
      "51/51 - 6s - loss: 1.0391 - first_order_loss: 0.6826 - second_order_loss: 0.3565\n",
      "Epoch 9/50\n",
      "51/51 - 5s - loss: 1.0275 - first_order_loss: 0.6762 - second_order_loss: 0.3513\n",
      "Epoch 10/50\n",
      "51/51 - 5s - loss: 0.9885 - first_order_loss: 0.6732 - second_order_loss: 0.3153\n",
      "Epoch 11/50\n",
      "51/51 - 6s - loss: 0.9885 - first_order_loss: 0.6645 - second_order_loss: 0.3241\n",
      "Epoch 12/50\n",
      "51/51 - 6s - loss: 0.9554 - first_order_loss: 0.6627 - second_order_loss: 0.2926\n",
      "Epoch 13/50\n",
      "51/51 - 6s - loss: 0.9552 - first_order_loss: 0.6532 - second_order_loss: 0.3020\n",
      "Epoch 14/50\n",
      "51/51 - 6s - loss: 0.9253 - first_order_loss: 0.6544 - second_order_loss: 0.2709\n",
      "Epoch 15/50\n",
      "51/51 - 6s - loss: 0.9229 - first_order_loss: 0.6435 - second_order_loss: 0.2793\n",
      "Epoch 16/50\n",
      "51/51 - 6s - loss: 0.8972 - first_order_loss: 0.6470 - second_order_loss: 0.2502\n",
      "Epoch 17/50\n",
      "51/51 - 5s - loss: 0.8922 - first_order_loss: 0.6363 - second_order_loss: 0.2558\n",
      "Epoch 18/50\n",
      "51/51 - 6s - loss: 0.8692 - first_order_loss: 0.6415 - second_order_loss: 0.2277\n",
      "Epoch 19/50\n",
      "51/51 - 8s - loss: 0.8600 - first_order_loss: 0.6335 - second_order_loss: 0.2265\n",
      "Epoch 20/50\n",
      "51/51 - 8s - loss: 0.8437 - first_order_loss: 0.6340 - second_order_loss: 0.2097\n",
      "Epoch 21/50\n",
      "51/51 - 8s - loss: 0.8327 - first_order_loss: 0.6256 - second_order_loss: 0.2071\n",
      "Epoch 22/50\n",
      "51/51 - 7s - loss: 0.8169 - first_order_loss: 0.6328 - second_order_loss: 0.1841\n",
      "Epoch 23/50\n",
      "51/51 - 7s - loss: 0.8086 - first_order_loss: 0.6219 - second_order_loss: 0.1867\n",
      "Epoch 24/50\n",
      "51/51 - 8s - loss: 0.7955 - first_order_loss: 0.6300 - second_order_loss: 0.1655\n",
      "Epoch 25/50\n",
      "51/51 - 7s - loss: 0.7872 - first_order_loss: 0.6192 - second_order_loss: 0.1680\n",
      "Epoch 26/50\n",
      "51/51 - 7s - loss: 0.7765 - first_order_loss: 0.6276 - second_order_loss: 0.1490\n",
      "Epoch 27/50\n",
      "51/51 - 8s - loss: 0.7664 - first_order_loss: 0.6162 - second_order_loss: 0.1502\n",
      "Epoch 28/50\n",
      "51/51 - 7s - loss: 0.7602 - first_order_loss: 0.6255 - second_order_loss: 0.1347\n",
      "Epoch 29/50\n",
      "51/51 - 7s - loss: 0.7481 - first_order_loss: 0.6136 - second_order_loss: 0.1345\n",
      "Epoch 30/50\n",
      "51/51 - 8s - loss: 0.7449 - first_order_loss: 0.6240 - second_order_loss: 0.1209\n",
      "Epoch 31/50\n",
      "51/51 - 7s - loss: 0.7340 - first_order_loss: 0.6123 - second_order_loss: 0.1217\n",
      "Epoch 32/50\n",
      "51/51 - 7s - loss: 0.7326 - first_order_loss: 0.6227 - second_order_loss: 0.1099\n",
      "Epoch 33/50\n",
      "51/51 - 8s - loss: 0.7200 - first_order_loss: 0.6104 - second_order_loss: 0.1096\n",
      "Epoch 34/50\n",
      "51/51 - 7s - loss: 0.7206 - first_order_loss: 0.6213 - second_order_loss: 0.0993\n",
      "Epoch 35/50\n",
      "51/51 - 6s - loss: 0.7088 - first_order_loss: 0.6092 - second_order_loss: 0.0996\n",
      "Epoch 36/50\n",
      "51/51 - 6s - loss: 0.7105 - first_order_loss: 0.6202 - second_order_loss: 0.0903\n",
      "Epoch 37/50\n",
      "51/51 - 6s - loss: 0.7013 - first_order_loss: 0.6122 - second_order_loss: 0.0891\n",
      "Epoch 38/50\n",
      "51/51 - 6s - loss: 0.6995 - first_order_loss: 0.6157 - second_order_loss: 0.0839\n",
      "Epoch 39/50\n",
      "51/51 - 6s - loss: 0.6897 - first_order_loss: 0.6071 - second_order_loss: 0.0826\n",
      "Epoch 40/50\n",
      "51/51 - 6s - loss: 0.6931 - first_order_loss: 0.6182 - second_order_loss: 0.0749\n",
      "Epoch 41/50\n",
      "51/51 - 6s - loss: 0.6834 - first_order_loss: 0.6067 - second_order_loss: 0.0767\n",
      "Epoch 42/50\n",
      "51/51 - 6s - loss: 0.6883 - first_order_loss: 0.6182 - second_order_loss: 0.0701\n",
      "Epoch 43/50\n",
      "51/51 - 6s - loss: 0.6761 - first_order_loss: 0.6054 - second_order_loss: 0.0707\n",
      "Epoch 44/50\n",
      "51/51 - 6s - loss: 0.6822 - first_order_loss: 0.6174 - second_order_loss: 0.0648\n",
      "Epoch 45/50\n",
      "51/51 - 5s - loss: 0.6705 - first_order_loss: 0.6049 - second_order_loss: 0.0656\n",
      "Epoch 46/50\n",
      "51/51 - 5s - loss: 0.6773 - first_order_loss: 0.6166 - second_order_loss: 0.0606\n",
      "Epoch 47/50\n",
      "51/51 - 5s - loss: 0.6650 - first_order_loss: 0.6039 - second_order_loss: 0.0610\n",
      "Epoch 48/50\n",
      "51/51 - 6s - loss: 0.6732 - first_order_loss: 0.6166 - second_order_loss: 0.0567\n",
      "Epoch 49/50\n",
      "51/51 - 5s - loss: 0.6609 - first_order_loss: 0.6035 - second_order_loss: 0.0574\n",
      "Epoch 50/50\n",
      "51/51 - 5s - loss: 0.6696 - first_order_loss: 0.6158 - second_order_loss: 0.0537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b0a6e00c70>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(batch_size=10240, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE_embeddings = model.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=combine_embedding(train_df,LINE_embeddings)\n",
    "test_pos_df=combine_embedding(test_pos_df,LINE_embeddings)\n",
    "df_neg=combine_embedding(df_neg,LINE_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_neg,X_test_neg = train_test_split(df_neg, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pos=np.ones(len(train_df))\n",
    "y_train_neg=np.zeros(len(X_train_neg))\n",
    "y_test_pos=np.ones(len(test_pos_df))\n",
    "y_test_neg=np.zeros(len(X_test_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((train_df,X_train_neg))\n",
    "y_train = np.concatenate((y_train_pos,y_train_neg))\n",
    "X_test = np.concatenate((test_pos_df,X_test_neg))\n",
    "y_test = np.concatenate((y_test_pos,y_test_neg)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=400)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = RandomForestClassifier(n_estimators=400)\n",
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8403702880668062\n"
     ]
    }
   ],
   "source": [
    "predict_Y3 = clf3.predict(X_test)\n",
    "print(get_accuracy(predict_Y3, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train_pos_data.csv',header=0)\n",
    "train_df=train_df.astype(str)\n",
    "ori_df = ori_df.astype(str)\n",
    "test_pos_df=pd.read_csv('test_pos_data.csv',header=0)\n",
    "df_neg = pd.DataFrame(list(negative_edges), columns=['id_1', 'id_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_G = nx.from_pandas_edgelist(ori_df, 'id_1', 'id_2')\n",
    "train_G = nx.from_pandas_edgelist(train_df, 'id_1', 'id_2')\n",
    "for i in range(len(list(ori_G.nodes))):\n",
    "    train_G.add_node(list(ori_G.nodes)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.values\n",
    "test_pos_df=test_pos_df.values\n",
    "df_neg=df_neg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   13.5s remaining:   13.5s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   15.8s finished\n"
     ]
    }
   ],
   "source": [
    "model = DeepWalk(train_G, walk_length=10, num_walks=80, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1b0f1352d60>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(window_size=5, iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepWalk_embeddings = model.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(edges_embs ,open(\"DeepWalk_embeddings.p\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_walk_combine_embedding(data,embeddings):\n",
    "    i=0\n",
    "    X = []\n",
    "    for node1,node2 in data:\n",
    "        X.append(np.concatenate((data[i],embeddings[str(int(node1))],embeddings[str(int(node2))])))\n",
    "   # print(embeddings[str(int(data[0]))])\n",
    "        i+=1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=deep_walk_combine_embedding(train_df,DeepWalk_embeddings)\n",
    "test_pos_df=deep_walk_combine_embedding(test_pos_df,DeepWalk_embeddings)\n",
    "df_neg=deep_walk_combine_embedding(df_neg,DeepWalk_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_neg,X_test_neg = train_test_split(df_neg, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pos=np.ones(len(train_df))\n",
    "y_train_neg=np.zeros(len(X_train_neg))\n",
    "y_test_pos=np.ones(len(test_pos_df))\n",
    "y_test_neg=np.zeros(len(X_test_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((train_df,X_train_neg))\n",
    "y_train = np.concatenate((y_train_pos,y_train_neg))\n",
    "X_test = np.concatenate((test_pos_df,X_test_neg))\n",
    "y_test = np.concatenate((y_test_pos,y_test_neg)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=400)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = RandomForestClassifier(n_estimators=400)\n",
    "clf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9065040174968714\n"
     ]
    }
   ],
   "source": [
    "predict_Y4 = clf4.predict(X_test)\n",
    "print(get_accuracy(predict_Y4, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['Jaccard Coefficient', 'Pref. Attachment', 'Common Neighbors','Node2vec','LINE','DeepWalk','jc,pa,cn']\n",
    "ironmen = [0.8448205284148723, 0.8041718810306312, 0.8443702412837277, 0.9115507420965837, 0.8412650144442755, 0.9065040174968714,0.8566449515210348]\n",
    "\n",
    "ironmen_dict = {\n",
    "                \"Algorithm\": groups,\n",
    "                \"auc\": ironmen\n",
    "}\n",
    "\n",
    "# 建立 data frame\n",
    "ironmen_df = pd.DataFrame(ironmen_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jaccard Coefficient</td>\n",
       "      <td>0.844821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pref. Attachment</td>\n",
       "      <td>0.804172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Common Neighbors</td>\n",
       "      <td>0.844370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Node2vec</td>\n",
       "      <td>0.911551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LINE</td>\n",
       "      <td>0.841265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DeepWalk</td>\n",
       "      <td>0.906504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jc,pa,cn</td>\n",
       "      <td>0.856645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm       auc\n",
       "0  Jaccard Coefficient  0.844821\n",
       "1     Pref. Attachment  0.804172\n",
       "2     Common Neighbors  0.844370\n",
       "3             Node2vec  0.911551\n",
       "4                 LINE  0.841265\n",
       "5             DeepWalk  0.906504\n",
       "6             jc,pa,cn  0.856645"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ironmen_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
